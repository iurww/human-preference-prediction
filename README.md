# Human Preference Prediction

ä½¿ç”¨ DeBERTa-v3 æ¨¡å‹é¢„æµ‹äººç±»å¯¹ LLM å“åº”çš„åå¥½ã€‚

## é¡¹ç›®ç»“æ„

```
human-preference/
â”œâ”€â”€ pyproject.toml          # UV åŒ…ç®¡ç†é…ç½®
â”œâ”€â”€ requirements.txt        # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ setup.sh               # ä¸€é”®è®¾ç½®è„šæœ¬
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ src/
â”‚   â””â”€â”€ __init__.py        # ç©ºæ–‡ä»¶ï¼Œç”¨äºåŒ…ç»“æ„
â”œâ”€â”€ scripts/               # æ‰€æœ‰ Python è„šæœ¬
â”‚   â”œâ”€â”€ download_data.py   # æ•°æ®ä¸‹è½½
â”‚   â”œâ”€â”€ train.py          # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ train_advanced.py # é«˜çº§è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ inference.py      # æ¨ç†è„šæœ¬
â”œâ”€â”€ data/                 # æ•°æ®ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ sample_submission.csv
â”œâ”€â”€ models/               # æ¨¡å‹ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â”‚   â””â”€â”€ best_model/
â””â”€â”€ *.log                 # è®­ç»ƒæ—¥å¿—æ–‡ä»¶
```

## å¿«é€Ÿå¼€å§‹

### æ–¹æ³• 1ï¼šä½¿ç”¨ä¸€é”®è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
uv venv
source .venv/bin/activate  # Linux/macOS
# .venv\Scripts\activate   # Windows

# 2. åˆ›å»ºå¿…è¦çš„æ–‡ä»¶å’Œç›®å½•
mkdir -p src scripts
touch src/__init__.py

# 3. å°†æ‰€æœ‰è„šæœ¬ç§»åˆ° scripts/ ç›®å½•
# (download_data.py, train.py, train_advanced.py, inference.py)

# 4. è¿è¡Œè®¾ç½®è„šæœ¬
chmod +x setup.sh
./setup.sh

# 5. é…ç½® Kaggle API
# åˆ›å»º ~/.kaggle/kaggle.json:
# {"username": "your_username", "key": "your_api_key"}

# 6. ä¸‹è½½æ•°æ®
python scripts/download_data.py

# 7. è®­ç»ƒæ¨¡å‹
python scripts/train.py

# 8. ç”Ÿæˆé¢„æµ‹
python scripts/inference.py
```

### æ–¹æ³• 2ï¼šæ‰‹åŠ¨å®‰è£…

```bash
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
uv venv
source .venv/bin/activate

# 2. åˆ›å»ºç›®å½•ç»“æ„
mkdir -p src scripts data models
touch src/__init__.py

# 3. å®‰è£…ä¾èµ–ï¼ˆä½¿ç”¨ requirements.txtï¼‰
uv pip install -r requirements.txt

# æˆ–è€…ç›´æ¥å®‰è£…
uv pip install torch transformers datasets pandas numpy scikit-learn wandb tqdm kaggle

# 4. é…ç½® Kaggle å’Œ WandB
# ... (è§ä¸‹æ–‡)

# 5. è¿è¡Œè„šæœ¬
python scripts/download_data.py
python scripts/train.py
python scripts/inference.py
```

## é…ç½®è¯´æ˜

### 1. Kaggle API é…ç½®

åˆ›å»º `~/.kaggle/kaggle.json` æ–‡ä»¶ï¼š

```json
{
  "username": "your_username",
  "key": "your_api_key"
}
```

è·å– API keyï¼šhttps://www.kaggle.com/settings/account

è®¾ç½®æƒé™ï¼ˆLinux/macOSï¼‰ï¼š
```bash
chmod 600 ~/.kaggle/kaggle.json
```

### 2. WandB é…ç½®

```bash
wandb login
```

è¾“å…¥ä½ çš„ API keyï¼ˆä» https://wandb.ai/authorize è·å–ï¼‰

## ä½¿ç”¨æ–¹æ³•

### 1. ä¸‹è½½æ•°æ®

```bash
python scripts/download_data.py
```

**è¾“å‡ºæ—¥å¿—ç¤ºä¾‹ï¼š**
```
2024-01-01 10:00:00 - __main__ - INFO - Data directory created/verified
2024-01-01 10:00:01 - __main__ - INFO - Downloading dataset from Kaggle...
2024-01-01 10:00:10 - __main__ - INFO - Dataset downloaded successfully
2024-01-01 10:00:11 - __main__ - INFO - Dataset extracted successfully
============================================================
Data files:
  - train.csv (45.23 MB)
  - test.csv (11.34 MB)
  - sample_submission.csv (0.89 MB)
============================================================
```

### 2. è®­ç»ƒæ¨¡å‹

```bash
python scripts/train.py
```

**åŠŸèƒ½ç‰¹æ€§ï¼š**
- âœ… ä½¿ç”¨ logging æ¨¡å—è®°å½•æ‰€æœ‰ä¿¡æ¯
- âœ… è‡ªåŠ¨åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†ï¼ˆ90%/10%ï¼‰
- âœ… WandB è®°å½•æ‰€æœ‰è®­ç»ƒæŒ‡æ ‡
- âœ… è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
- âœ… ç”Ÿæˆ train.log æ—¥å¿—æ–‡ä»¶

**è®­ç»ƒæ—¥å¿—ç¤ºä¾‹ï¼š**
```
2024-01-01 10:00:00 - __main__ - INFO - ============================================================
2024-01-01 10:00:00 - __main__ - INFO - Starting training with configuration:
2024-01-01 10:00:00 - __main__ - INFO -   model_name: microsoft/deberta-v3-base
2024-01-01 10:00:00 - __main__ - INFO -   batch_size: 8
2024-01-01 10:00:00 - __main__ - INFO -   learning_rate: 2e-05
...
2024-01-01 10:00:05 - __main__ - INFO - Using device: cuda
2024-01-01 10:00:05 - __main__ - INFO - GPU: NVIDIA GeForce RTX 3090
2024-01-01 10:00:06 - __main__ - INFO - Train size: 41383, Validation size: 4598
...
2024-01-01 10:15:23 - __main__ - INFO - [Train] Loss: 0.8234, Log Loss: 0.8156
2024-01-01 10:16:45 - __main__ - INFO - [Val]   Loss: 0.7845, Log Loss: 0.7823
2024-01-01 10:16:45 - __main__ - INFO - ğŸ‰ New best validation log loss: 0.7823
```

### 3. ç”Ÿæˆé¢„æµ‹

```bash
python scripts/inference.py
```

**è¾“å‡ºæ—¥å¿—ç¤ºä¾‹ï¼š**
```
2024-01-01 11:00:00 - __main__ - INFO - ============================================================
2024-01-01 11:00:00 - __main__ - INFO - Starting inference
2024-01-01 11:00:00 - __main__ - INFO - ============================================================
2024-01-01 11:00:01 - __main__ - INFO - Using device: cuda
2024-01-01 11:00:02 - __main__ - INFO - Test samples: 11496
...
2024-01-01 11:02:34 - __main__ - INFO - Submission saved to submission.csv
2024-01-01 11:02:34 - __main__ - INFO - ============================================================
2024-01-01 11:02:34 - __main__ - INFO - Prediction Statistics:
2024-01-01 11:02:34 - __main__ - INFO -   Model A wins (avg): 0.3245
2024-01-01 11:02:34 - __main__ - INFO -   Model B wins (avg): 0.4123
2024-01-01 11:02:34 - __main__ - INFO -   Ties (avg): 0.2632
2024-01-01 11:02:34 - __main__ - INFO - ============================================================
```

### 4. æäº¤åˆ° Kaggle

```bash
kaggle competitions submit -c human-preference -f submission.csv -m "DeBERTa-v3-base submission"
```

## æ¨¡å‹é…ç½®

åœ¨ `scripts/train.py` ä¸­ä¿®æ”¹é…ç½®ï¼š

```python
CONFIG = {
    'model_name': 'microsoft/deberta-v3-base',  # æ¨¡å‹åç§°
    'max_length': 512,                          # æœ€å¤§åºåˆ—é•¿åº¦
    'batch_size': 8,                            # æ‰¹æ¬¡å¤§å°
    'learning_rate': 2e-5,                      # å­¦ä¹ ç‡
    'num_epochs': 3,                            # è®­ç»ƒè½®æ•°
    'warmup_ratio': 0.1,                        # é¢„çƒ­æ¯”ä¾‹
    'weight_decay': 0.01,                       # æƒé‡è¡°å‡
    'seed': 42,                                 # éšæœºç§å­
}
```

### æ¨èé…ç½®

**å¿«é€Ÿå®éªŒ**ï¼ˆéœ€è¦ 8GB GPUï¼‰ï¼š
```python
CONFIG = {
    'model_name': 'microsoft/deberta-v3-base',
    'batch_size': 8,
    'num_epochs': 3,
}
```

**é«˜æ€§èƒ½**ï¼ˆéœ€è¦ 16GB+ GPUï¼‰ï¼š
```python
CONFIG = {
    'model_name': 'microsoft/deberta-v3-large',
    'batch_size': 4,
    'max_length': 768,
    'num_epochs': 5,
}
```

**CPU è®­ç»ƒ**ï¼š
```python
CONFIG = {
    'model_name': 'microsoft/deberta-v3-base',
    'batch_size': 2,
    'num_epochs': 1,
}
```

## æ—¥å¿—ç³»ç»Ÿ

é¡¹ç›®ä½¿ç”¨ Python logging æ¨¡å—ï¼Œæ‰€æœ‰æ—¥å¿—ä¼šï¼š
- è¾“å‡ºåˆ°æ§åˆ¶å°
- ä¿å­˜åˆ° `train.log` æ–‡ä»¶

**æ—¥å¿—çº§åˆ«ï¼š**
- INFO: æ­£å¸¸è¿è¡Œä¿¡æ¯
- WARNING: è­¦å‘Šä¿¡æ¯
- ERROR: é”™è¯¯ä¿¡æ¯

## WandB ç›‘æ§æŒ‡æ ‡

è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨è®°å½•ï¼š

| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| `train_loss` | è®­ç»ƒæŸå¤± |
| `train_log_loss` | è®­ç»ƒé›† Log Loss |
| `val_loss` | éªŒè¯æŸå¤± |
| `val_log_loss` | éªŒè¯é›† Log Lossï¼ˆä¸»è¦æŒ‡æ ‡ï¼‰â­ |
| `learning_rate` | å½“å‰å­¦ä¹ ç‡ |
| `best_val_log_loss` | æœ€ä½³éªŒè¯ Log Loss |

åœ¨ WandB ç½‘é¡µç«¯æŸ¥çœ‹ï¼šhttps://wandb.ai/

## è¯„ä¼°æŒ‡æ ‡

ä½¿ç”¨ **Log Loss** è¿›è¡Œè¯„ä¼°ï¼š

$$
\text{LogLoss} = -\frac{1}{N}\sum_{i=1}^{N}\sum_{c \in \{A,B,TIE\}} \mathbf{1}(y_i = c) \log p_{i,c}
$$

- $N$: æ ·æœ¬æ•°é‡
- $y_i$: çœŸå®æ ‡ç­¾
- $p_{i,c}$: é¢„æµ‹æ¦‚ç‡

**è¶Šå°è¶Šå¥½** âœ…

## å¸¸è§é—®é¢˜

### Q1: UV å®‰è£…å¤±è´¥

**é”™è¯¯ï¼š** `Failed to build human-preference-prediction`

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# ä¸ä½¿ç”¨ -e æ¨¡å¼ï¼Œç›´æ¥å®‰è£…ä¾èµ–
mkdir -p src
touch src/__init__.py
uv pip install -r requirements.txt
```

### Q2: GPU å†…å­˜ä¸è¶³

**é”™è¯¯ï¼š** `CUDA out of memory`

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# åœ¨ train.py ä¸­è°ƒæ•´
CONFIG = {
    'batch_size': 4,  # æˆ–æ›´å°ï¼Œå¦‚ 2
    'max_length': 256,  # å‡å°åºåˆ—é•¿åº¦
}
```

### Q3: Kaggle ä¸‹è½½å¤±è´¥

**é”™è¯¯ï¼š** `403 Forbidden`

**è§£å†³æ–¹æ¡ˆï¼š**
1. æ£€æŸ¥ `~/.kaggle/kaggle.json` æ˜¯å¦æ­£ç¡®
2. åœ¨ Kaggle ç½‘ç«™ä¸Šæ¥å—æ¯”èµ›è§„åˆ™
3. æ£€æŸ¥ API key æ˜¯å¦è¿‡æœŸ

### Q4: è®­ç»ƒé€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆï¼š**
- ä½¿ç”¨ GPUï¼ˆCUDAï¼‰è€Œä¸æ˜¯ CPU
- ä½¿ç”¨ `deberta-v3-base` è€Œä¸æ˜¯ `large`
- å¢åŠ  `batch_size`ï¼ˆå¦‚æœæ˜¾å­˜å…è®¸ï¼‰
- å‡å° `max_length`

### Q5: WandB æ— æ³•ç™»å½•

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# é‡æ–°ç™»å½•
wandb login --relogin

# æˆ–ä½¿ç”¨ç¯å¢ƒå˜é‡
export WANDB_API_KEY=your_api_key
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®å¢å¼º
```python
# äº¤æ¢ response_a å’Œ response_b
# åœ¨ PreferenceDataset ä¸­å®ç°
```

### 2. æ¨¡å‹é›†æˆ
```bash
# è®­ç»ƒå¤šä¸ªæ¨¡å‹
python scripts/train.py --seed 42
python scripts/train.py --seed 123
python scripts/train.py --seed 456

# é¢„æµ‹æ—¶å–å¹³å‡
```

### 3. æ›´é•¿çš„åºåˆ—
```python
CONFIG = {
    'max_length': 768,  # ä» 512 å¢åŠ åˆ° 768
}
```

### 4. å­¦ä¹ ç‡è°ƒä¼˜
```python
# å°è¯•ä¸åŒçš„å­¦ä¹ ç‡
learning_rates = [1e-5, 2e-5, 3e-5, 5e-5]
```

## é¡¹ç›®ç‰¹ç‚¹

- âœ… ä½¿ç”¨ UV åŒ…ç®¡ç†
- âœ… ä½¿ç”¨ logging æ¨¡å—è®°å½•æ—¥å¿—ï¼ˆä¸ä½¿ç”¨ printï¼‰
- âœ… WandB å®Œæ•´é›†æˆ
- âœ… è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
- âœ… å®Œæ•´çš„é”™è¯¯å¤„ç†
- âœ… è¯¦ç»†çš„æ—¥å¿—è¾“å‡º
- âœ… æ”¯æŒ GPU/CPU è®­ç»ƒ
- âœ… ä»£ç ç»“æ„æ¸…æ™°

## å‚è€ƒèµ„æº

- [DeBERTa-v3 è®ºæ–‡](https://arxiv.org/abs/2111.09543)
- [Transformers æ–‡æ¡£](https://huggingface.co/docs/transformers)
- [WandB æ–‡æ¡£](https://docs.wandb.ai/)
- [Kaggle ç«èµ›é¡µé¢](https://www.kaggle.com/c/human-preference)

## License

MIT